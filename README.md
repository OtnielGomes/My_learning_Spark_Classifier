# My Learning Witch PySpark Classifier
Hello,
We received a request to help the marketing team predict whether a customer will cancel the service or not, as they are noticing a problem with churn.

Our proposal for this problem is to create a machine learning model capable of classifying customers who will cancel the service and those who will not.

To do this, we will use a database provided by the marketing team containing information about this customer, such as the type of service they contracted, how long their contract has been in force, etc. With this information, we will create the model.

I will use PySpark to do this, mainly Spark DataFrame SQL mode and MLlib. With this tool we will carry out the entire machine learning pipeline, going through the data processing stage, adjusting the models using algorithms, optimizing these models by finding the best hyperparameters and, finally, validating the models.

At the end of the pipeline, we will deliver a model capable of classifying new customers as likely to cancel the service or not, offering this prediction. In other words, we will have a tuned model, optimized for our problem.

## üöÄ Starting

No link abaixo voc√™ pode obter uma c√≥pia do projeto:
* [C√≥pia do Projeto](https://github.com/OtnielGomes/My_Learning_With_Pyspark-Regression/archive/refs/heads/main.zip)

## üõ†Ô∏è Constru√≠do com:

* [Anaconda-Navigator](https://www.anaconda.com/)
* [Jupyter NoteBook](https://jupyter.org/install)
* [Python-3](https://www.python.org/downloads/)
* [Spark-3.5.0-bin-hadoop3.tgz](https://www.apache.org/dyn/closer.lua/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz)
## üì¶ Frameworks  

* Pandas
* Seaborn
* Matplotlib
* FindSpark
* PySpark.SQL
* PySpark.ML

* ## ‚öôÔ∏è Rodando o codigo:

### Comece pelo Notebook:
My_Learnig_With_Spark-Regression
